= AWS 환경에서 구축

본 장에서는 AWS 환경에서 폐쇄망으로 Kubespray를 이용하여 HyperCloud를 설치하는 방법에 대해서 설명한다.

설치하는 과정은 크게 다음과 같다.

. <<TerraformAws, Terraform 구성>>
. <<K8sInfraAws, 쿠버네티스 인프라 구성>>
. <<ArgoCDInstallAws, ArgoCD 설치>>
. <<MasterClusterAws, 마스터 클러스터 설치>>
. <<SingleClusterAws, 싱글 클러스터 설치>>
. <<ResourceDeployAws, 리소스 배포>>
. <<TraefikApiGatewayAws, Traefik 기반의  API 게이트웨이 구성>>

[#TerraformAws]
== Terraform 구성

Terraform을 이용하여 CSP(AWS, vSphere) 환경에서의 쿠버네티스 클러스터 구성을 위한 인프라 리소스를 생성할 수 있다.

.Terraform을 설치하기 위해서는 다음과 같은 사전 준비가 필요하다.(TD: 사전 방법에 대한 상세 설명이 필요한가? 필요하다면 참고 자료 요청)(QA: 필요없다고 생각합니다.)
[NOTE]
====
* IAM 계정 발급
* 액세스 키 ID 및 시크릿 키 저장
* 키페어 발급
====

Terraform을 구성하는 순서는 다음과 같다.

. <<TerraformInstallAws, Terraform 설치>>
. <<KubesprayDownTerraform, Kubespray 다운로드 (쿠버네티스 설치용)>>
. <<TerraformConfigAws, Terraform 환경 설정>>
. <<TerraformRunAws, Terraform 적용>>


[#TerraformInstallAws]
=== Terraform 설치

Terraform을 사용하기 위해 관련 패키지를 설치한다.

. *저장소 추가*
+
패키지 설치에 사용할 저장소를 추가한다.
+
----
$ sudo yum install -y yum-utils
$ sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
----

. *패키지 설치*
+
설치 가능한 Terraform의 버전을 확인한다.
+
----
$ yum --showduplicate list terraform
----
+
추가한 저장소에 Terraform을 설치한다.
+
----
$ sudo yum -y install terraform
----

. *설치 확인*
+
설치된 Terraform의 버전을 확인한다.
+
----
$ terraform  version
----

[#KubesprayDownTerraform]
=== Kubespray 다운로드 (쿠버네티스 설치용)

다음의 명령을 실행하여 쿠버네티스 설치를 위한 Kubespray를 다운로드한다.
----
$ git clone -b tmax-master https://github.com/tmax-cloud/kubespray.git ./kubespray-infra
----

[#TerraformConfigAws]
=== Terraform 환경 설정

`kubespray-infra/contrib/terraform/aws/terraform.tfvars` 파일을 열어 Terraform에 전달하는 변수의 값을 정의한다.
----
#Global Vars
aws_cluster_name = "terraform"

#VPC Vars
aws_vpc_cidr_block       = "20.0.0.0/16"
aws_cidr_subnets_public  = ["20.0.1.0/24", "20.0.2.0/24", "20.0.3.0/24"]
aws_cidr_subnets_private = ["20.0.6.0/24", "20.0.7.0/24", "20.0.8.0/24"]

#Bastion Host
aws_bastion_num  = 1
aws_bastion_size = "t2.medium"

#Kubernetes Cluster
aws_kube_master_num  = 3
aws_kube_master_size = "t2.medium"
aws_kube_master_disk_size = 50

aws_etcd_num  = 0
aws_etcd_size = "t2.medium"
aws_etcd_disk_size = 50

aws_kube_worker_num  = 1
aws_kube_worker_size = "t2.medium"
aws_kube_worker_disk_size = 50

#EC2 Source/Dest Check
aws_src_dest_check      = false

#Settings AWS ELB
aws_elb_api_port          = 6443
k8s_secure_api_port       = 6443
aws_elb_api_internal      = true
aws_elb_api_public_subnet = false

default_tags = {
    Env = "terraform-qatest"
    Product = "kubernetes"
    Team = "QA"
}

#Setting VPN Connection

vpn_connection_enable = true
customer_gateway_ip   = "175.195.163.15"
local_cidr            = "30.0.0.0/16"

inventory_file = "../../../inventory/tmaxcloud/hosts"
----

[#TerraformRunAws]
=== Terraform 적용

변경된 Terraform의 환경 설정을 적용하기 위해 AWS 계정 및 액세스 키 정보를 등록한다.

. *AWS 계정 및 액세스 키 정보 등록*
+
`credentials.tfvars` 파일을 생성한 후 사전에 발급받은 AWS 액세스 키 ID와 보안 액세스 키 정보를 등록한다.
+
.예시
----
#AWS Access Key
AWS_ACCESS_KEY_ID = "AKIAVVIW**********"
#AWS Secret Key
AWS_SECRET_ACCESS_KEY = "oa3ph/GBPkO5Km8rlM*********************"
#EC2 SSH Key Name
AWS_SSH_KEY_NAME = "default"
#AWS Region
AWS_DEFAULT_REGION = "us-east-x"
----

. *AWS 계정 및 액세스 키 정보 적용* 
+
AWS 액세스 키 ID와 보안 액세스 키 정보가 등록된 `credentials.tfvars` 파일을 *terraform apply* 명령을 사용하여 적용한다.
+
----
terraform apply -var-file=credentials.tfvars
----

[#K8sInfraAws]
== 쿠버네티스 인프라 구성

본 절에서는 Kubespray를 이용하여 쿠버네티스 인프라를 구성하는 방법에 대해서 설명한다.

쿠버네티스 인프라를 구성하는 순서는 다음과 같다.

. <<KubesprayConfigK8sAws, Kubespray 환경 설정>>
. <<KubesprayRunK8sAws, Kubespray 실행>>

[#KubesprayConfigK8sAws]
=== Kubespray 환경 설정

Kubespray를 실행하기 위한 필수 설정 파일들을 정의한다.

NOTE: Kubespray를 실행하기 위해서는 사전 준비가 필요하다. 반드시  xref:offline-intro.adoc[설치 전 준비사항]을 참고하여 환경을 구성한다.

. *노드 정보 등록*
+ 
`kubespray-argocd/inventory/tmaxcloud/inventory.ini` 파일을 열어 kubespray에서 설치할 노드들의 정보를 등록한다. +
이때 all 그룹은 `*[호스트 이름] [Ansible IP 주소] [Backup IP 주소]*` 형태로 작성하고, 그 외 그룹은 all 그룹에서 정의한 호스트 이름만 작성한다.

. *쿠버네티스 기본 정보 설정*
+
`kubespray-infra/inventory/tmaxcloud/group_vars/all/all.yml` 파일을 열어 Kubernetes의 기본 정보를 설정한다.
+
.예시
----
apiserver_loadbalancer_domain_name: "10.0.10.50" <1> (QA: aws elb 주소 입력 "kubernetes-nlb-test-xxx.elb.us-east-x.amazonaws.com" ) 
loadbalancer_apiserver:
  address: 10.0.10.50 <2> (QA: aws에서는 쓰이지 않습니다. 주석처리)
  port: 6443 <3>
  
upstream_dns_servers: <4>
  - 192.168.1.150  (QA: aws dns server 는 20.0.0.2 입니다. 20.0.0.2로 교체)
----
+
<1> 쿠버네티스 API 서버 주소 (QA: aws elb 주소)
* 싱글 마스터의 경우: 마스터 노드의 IP 주소 (QA: 삭제)
* 멀티 마스터의 경우: API 서버와 통신할 수 있는 VIP 주소 (QA: 삭제) 
<2> 쿠버네티스 API 서버와 통신할 수 있는 VIP 주소 (QA: 주석처리한 항목입니다. 삭제)
<3> 쿠버네티스 API 서버 포트 번호
<4> 도메인 네임서버 주소 (QA: aws 도메인 네임서버 주소)
 
. *Calico 구성 정보 설정*
+
`kubespray-infra/inventory/tmaxcloud/k8s_cluster/k8s-net-calico.yml` 파일을 열어 Calico 관련 정보를 설정한다.
+
.예시
----
(QA: calico_ipip_mode: 'Always' 추가) <1>
calico_ip_auto_method: "cidr=192.168.7.0/24" <2>
----
+
<1>(QA: calico IP_in_IP 모드 설정)
<2> Calico가 자동으로 감지할 노드들의 CIDR 값 

. *추가 설치 모듈 설정*
+
`kubespray-infra/inventory/tmaxcloud/k8s_cluster/addons.yml` 파일을 열어 추가 설치가 가능한 모듈 관련 정보를 설정한다.
+
.예시
----
default_storageclass_name: efs-sc <1>
sc_name_0: efs-sc-0 <2>
sc_name_999: efs-sc-999 <3>
aws_efs_csi_namespace: aws-efs-csi <4>
aws_efs_filesystem_id: fs-XXX <5>
----
+
<1> 기본값으로 설정할 스토리지 이름
<2> HyperRegistry에서 Postgres PVC의 스토리지 클래스 이름
<3> 그 외의 PVC 스토리지 클래스 이름
<4> AWS EFS CSI 스토리지의 네임스페이스 이름
<5> AWS EFS 파일 시스템의 ID

. *폐쇄망 정보 설정*
+
`kubespray-infra/inventory/tmaxcloud/group_vars/all/offline.yml` 파일을 열어 폐쇄망 관련 정보를 설정한다.
+
.예시
----
is_this_offline: true <1>
registry_host: "10.0.10.50:5000" <2>
files_repo: "http://172.22.5.2" <3>
----
+
<1> 폐쇄망 환경 여부 (폐쇄망일 경우 true)
<2> 프라이빗 레지스트리 주소
<3> 파일 리포지터리 주소

. *IP 주소 대역 설정*
+
`kubespray-infra/inventory/tmaxcloud/group_vars/k8s_cluster/k8s-cluster.yml` 파일을 열어 파드 및 서비스의 IP 주소 대역 정보를 설정한다.
+
.예시
----
# Kubernetes internal network for services, unused block of space.
kube_service_addresses: 10.96.0.0/24 <1>

# internal network. When used, it will assign IP
# addresses from this range to individual pods.
# This network must be unused in your network infrastructure!
kube_pods_subnet: 10.244.0.0/24 <2>
----
+
<1> 서비스 IP 주소 대역
<2> 파드 서브넷 IP 주소 대역

[#KubesprayRunK8sAws]
=== Kubespray 실행

ansible-playbook 명령을 사용하여 Kubespray를 실행한다.
----
$ ansible-playbook -i inventory/tmaxcloud/inventory.ini --become --become-user=root cluster.yml
(QA: ansible-playbook -i ./inventory/tmaxcloud/inventory.ini ./cluster.yml -e ansible_user=ec2-user -e bootstrap_os=centos -e ansible_ssh_private_key_file={pem 파일 위치} -e cloud_provider=aws -b --become-user=root --flush-cache -v )
----

[#ArgoCDInstallOn]
== ArgoCD 설치

본 절에서는 Kubespray를 이용하여 ArgoCD를 설치하는 방법에 대해서 설명한다.

ArgoCD를 설치하는 순서는 다음과 같다.

. <<KubesprayDownArgoAws, Kubespray 다운로드 (ArgoCD 설치용)>>
. <<KubesprayConfigArgoAws, Kubespray 환경 설정>>
. <<KubesprayRunArgoAws, Kubespray 실행>>

[#KubesprayDownArgoAws]
=== Kubespray 다운로드 (ArgoCD 설치용)

다음의 명령을 실행하여 ArgoCD 설치를 위한 Kubespray를 다운로드한다.
----
$ git clone -b ck1room https://github.com/tmax-cloud/kubespray.git ./kubespray-argocd
----

[#KubesprayConfigArgoAws]
=== Kubespray 환경 설정

Kubespray를 실행하기 위한 필수 설정 파일들을 정의한다.

NOTE: Kubespray를 실행하기 위해서는 사전 준비가 필요하다. 반드시  xref:offline-intro.adoc[설치 전 준비사항]을 참고하여 환경을 구성한다.

. *노드 정보 등록*
+ 
`kubespray-argocd/inventory/tmaxcloud/inventory.ini` 파일을 열어 kubespray에서 설치할 노드들의 정보를 등록한다. +
이때 all 그룹은 `*[호스트 이름] [Ansible IP 주소] [Backup IP 주소]*` 형태로 작성하고, 그 외 그룹은 all 그룹에서 정의한 호스트 이름만 작성한다.

. *폐쇄망 정보 설정*
+
`kubespray-argocd/inventory/tmaxcloud/group_vars/all/offline.yml` 파일을 열어 폐쇄망 관련 정보를 설정한다.
+
.예시
----
is_this_offline: true <1>
registry_host: "10.0.10.50:5000" <2>
files_repo: "http://172.22.5.2" <3>
----
+
<1> 폐쇄망 환경 여부 (폐쇄망일 경우 true)
<2> 프라이빗 레지스트리 주소
<3> 파일 리포지터리 주소

. *사용자 지정 도메인 등록*
+
`kubespray-argocd/inventory/tmaxcloud/group_vars/k8s_cluster/k8s-cluster.yml` 파일을 열어 외부에 노출할 사용자 지정 도메인의 정보를 등록한다.
+
.예시
----
# Enable extra custom DNS domain - by sophal_hong@tmax.co.kr
enable_local_nip_domain: false <1>
enable_custom_domain: true <2>
custom_domain_name: "cloudqa.com" <3>
custom_domain_ip: 172.22.7.2 <4>
api_server_dns_cfwhn: true <5>

# Kubernetes internal network for services, unused block of space.
kube_service_addresses: 10.96.0.0/24 <6>

# internal network. When used, it will assign IP
# addresses from this range to individual pods.
# This network must be unused in your network infrastructure!
kube_pods_subnet: 10.244.0.0/24 <7>
----
+
<1> nip.io 도메인의 사용 여부 (Self-Signed 도메인을 사용할 경우 true)
<2> 커스텀 도메인의 사용 여부 (DNS를 사용할 경우 true)
<3> 프록시 노드에 맵핑된 DNS 이름
<4> 프록시 노드의 IP 주소 
<5> kube-apiserver의 DNS 정책으로 "ClusterFirstWithHostNet" 적용 여부 
<6> 서비스 IP 주소 대역
<7> 파드 서브넷 IP 주소 대역

. *설치할 애플리케이션 구성 정보 확인*
+
Kubespray로 설치될 애플리케이션(`nginx`, `harbor`, `gitlab`, `argocd`)의 구성 정보를 확인 및 설정한다. +
해당 애플리케이션의 구성 정보는 기본적으로 `kubespray-argocd/roles/bootstrap-cloud/defaults/main.yml` 파일에서 설정이 가능하며, 추가적으로 커스터마이징이 필요할 경우에는 `kubespray-argocd/roles/bootstrap-cloud/task/` 및 `kubespray-argocd/roles/bootstrap-cloud/templates/` 하위 파일에서 설정이 가능하다. (TD: 파일의 풀경로가 정상적으로 작성되었는지 확인 필요)(QA: 맞습니다.)
+
다음은 인그레스의 서비스 타입을 "NodePort"로 설정하는 예이다. (QA: aws elb(elastic loadbalancer)를 사용하기 위해 서비스 타입을 LoadBalancer 로 설정해야 합니다.)
+
.kubespray-argocd/roles/bootstrap-cloud/defaults/main.yml 
----
ingress_nginx_service_type: NodePort (QA: LoadBalancer)
----

[#KubesprayRunArgoAws]
=== Kubespray 실행

ansible-playbook 명령을 사용하여 애플리케이션을 설치한다.
----
$ (QA: ansible-playbook -i ./inventory/tmaxcloud/inventory.ini ./cluster.yml -t bootstrap-cloud -e ansible_user=ec2-user -e bootstrap_os=centos -e ansible_ssh_private_key_file={pem 파일 위치} -e cloud_provider=aws -b --become-user=root --flush-cache -v )
----

NOTE: 애플리케이션 설치가 정상적으로 완료되면, Gitlab과 ArgoCD 간의 저장소가 자동으로 연동된다.

[#MasterClusterAws]
== 마스터 클러스터 설치

. *master-values.yaml 파일 수정*
+
`application/helm/master-values.yaml` 파일을 열어 애플리케이션을 Helm Chart로 설치하기 위해 사용할 환경 변수를 정의한다.
+
.예시
----
...
global:
  privateRegistry: 10.0.0.1:5000 <1>
...
  gatewayBootstrap:
    enabled: true <2>
    svc_type: NodePort <3> (QA: LoadBalancer)
    tls:
      selfsigned:
        enabled: true <4>
...
----
+
<1> 프라이빗 컨테이너 이미지 레지스트리의 주소
<2> 게이트웨이 부트스트랩의 포함 여부
<3> 네트워크 서비스 타입 
<4> 자체 서명 인증서의 사용 여부
+
NOTE: 예시 외에 설치할 모듈에 대한 enabled 값을 true로 설정하거나, 필요시 사용자 지정 도메인을 등록한다.

. *shared-values.yaml 파일 수정*
+
`application/helm/shared-values.yaml` 파일을 열어 마스터 클러스터에 필요한 구성 정보를 설정한다.
+
.예시
----
...
    repoURL: https://gitlab.cloudqa.com/root/argocd-installer.git <1>
...
global:
  network:
    disabled: true <2>
  domain: cloudqa.com <3>
  keycloak:
    domain: hyperauth.cloudqa.com <4>
...
----
<1> ArgoCD와 연동된 Gitlab 저장소 주소 (Gitlab의 경우 url 마지막에 .git을 추가)
<2> 폐쇄망 환경 여부 (폐쇄망일 경우 true)
<3> 애플리케이션 설치 시 인그레스 주소에 사용될 커스텀 도메인 이름
<4> 설치할 HyperAuth 도메인 이름

. *애플리케이션 변수 설정*
+
`application/app_of_apps/master-applications.yaml` 파일을 열어 마스터 클러스터의 애플리케이션 변수를 설정한다.
+
.예시
----
spec:
  ...
  source:
    ...
    repoURL: https://gitlab.cloudqa.com/root/argocd-installer.git <1> 
    targetRevision: HEAD <2>
----
<1> ArgoCD와 연동된 Gitlab 저장소 주소 (Gitlab의 경우 url 마지막에 .git을 추가)
<2> Gitlab에 연동되어 있는 argocd-installer의 브랜치 이름

. *애플리케이션 등록*
+
설치 환경에 애플리케이션을 등록한다.
+
----
$ kubectl -n argocd apply -f application/app_of_apps/master-applications.yaml
----

[#SingleClusterAws]
== 싱글 클러스터 설치

. *애플리케이션 파일 생성*
+
싱글 클러스터 생성을 위해 ArgoCD에 띄울 템플릿 파일을 생성한다. +
이때 생성할 파일의 이름은 `{네임스페이스 이름}-{클러스터 이름}-applications.yaml` 형태로 생성한다.
+
.예시
----
$ cp application/app_of_apps/single-applications.yaml application/app_of_apps/default-cluster-applications.yaml
----

. *애플리케이션 변수 설정*
+
1번 과정에서 생성한 파일에 싱글 클러스터의 애플리케이션 변수를 설정한다. 이때 설정 항목에 대한 자세한 설명은 해당 파일 내의 주석을 참고한다.

. *애플리케이션 등록*
+
1번 과정에서 생성한 파일을 사용하여 마스터 클러스터 환경에 애플리케이션을 등록한다.
+
.예시
----
$ kubectl -n argocd apply -f application/app_of_apps/default-cluster-applications.yaml
----

[#ResourceDeployAws]
== 리소스 배포

애플리케이션 동기화 작업을 통해 리소스를 배포한다.

CAUTION: 애플리케이션 동기화 순서는 다음과 같다. 반드시 순서에 맞게 동기화 작업을 수행한다. + 
1. api-gateway-bootstrap(cert-manager + api-gateway) +
2. strimzi kafka operator +
3. hyperauth +
4. efk or opensearch +
5. prometheus +
6. grafana +
7. istio +
8. jaeger +
9. kiali +
10. cluster-api +
11. cluster-api-provider-aws +
12. cluster-api-provider-vsphere +
13. template-service-broker +
14. catalog-controller +
15. hypercloud +
16. tekton-pipeline +
17. tekton-trigger +
18. cicd-operator +
19. redis-operator +
20. image-validating-webhook +
21. ai-devops

. *ArgoCD 서버 접속* (QA: argocd 콘솔 접속용 id, password 찾기도 추가, 초기 pw가 난수로 되어있어서 찾는 방법도 필요합니다.)
+
ArgoCD 서버에 접속한 후 로그인한다. 이때 ArgoCD 서버의 주소는 다음의 명령어를 실행하여 확인할 수 있다.
+
----
$ kubectl get svc -n argocd argocd-server
----
(QA: argocd 콘솔 접속용 id : admin, password는 아래 명령어를 통해 접속 후 왼쪽 메뉴바의 user info에서 update password를 통해 비밀번호를 변경한다.)
----
$ kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
----

. *동기화할 애플리케이션 검색*
+
동기화 작업을 수행할 애플리케이션을 검색한 후 *[SYNC]* 버튼을 클릭한다.
+
image::../images/figure_application_sync_01.png[]

. *동기화 옵션 설정*
+
동기화할 리소스 및 동기화 옵션을 설정한 후 *[SYNCHRONIZE]* 버튼을 클릭한다.
+
image::../images/figure_application_sync_02.png[]

. *상태 확인*
+
애플리케이션의 *Status* 항목에 "Healthy"와 "Synced"가 표시되는지 확인한다.
+
image::../images/figure_application_sync_03.png[]

[#TraefikApiGatewayAws]
== Traefik 기반의  API 게이트웨이 구성 (TD: 전체 내용 검수 필요)

Gitlab과 ArgoCD에서 Traefik 게이트웨이를 사용하도록 설정한다. (QA: argocd에서 application을 sync 하면 자동적으로 traefik 게이트웨이가 깔리는데 깔린 후 인그레스 리소스를 수정해야 합니다.)

=== Gitlab
. 다음의 명령을 실행하여 Gitlab에 대해 인그레스 리소스를 편집한다.
+
----
$ kubectl edit ingress -n gitlab-system gitlab-ingress
----
. 편집 모드에서 다음과 같이 정보를 추가한다.
+
----
...
metadata:
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: websecure <1>
...
  labels:
    ingress.tmaxcloud.org/name: gitlab <2>
...
spec:
  ingressClassName: tmax-cloud <3>
...
----
<1> 주석 추가
<2> 레이블 추가
<3> 인그레스 클래스 추가

=== ArgoCD
. 다음의 명령을 실행하여 ArgoCD에 대해 인그레스 리소스를 편집한다.
+
----
$ kubectl edit ingress -n argocd argocd-server-ingress
----
. 편집 모드에서 다음과 같이 정보를 추가 및 수정한다.
+
----
...
metadata:
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: websecure <1>
...
  labels:
    ingress.tmaxcloud.org/name: argocd <2>
...
spec:
  ingressClassName: tmax-cloud <3>
  rules:
    http:
      paths:
      - backend:
          serviceName: argocd-server
          servicePort: http <4>
...
----
<1> 주석 추가
<2> 레이블 추가
<3> 인그레스 클래스 추가
<4> 트래픽을 처리할 서비스 포트를 ``http``로 수정
