= 온프레미스 환경에서 구축

본 장에서는 온프레미스 환경에서 폐쇄망으로 Kubespray를 이용하여 HyperCloud를 설치하는 방법에 대해서 설명한다.

설치하는 과정은 크게 다음과 같다.

. <<Kubespray 다운로드>>
. <<Kubespray 환경 설정>>
. <<Kubespray 실행>>
. <<환경 설정>>
. <<마스터 클러스터 설치>>
. <<싱글 클러스터 설치>>
. <<리소스 배포>>


[#Kubespray 다운로드]
== Kubespray 다운로드
Kubespray는 Kubeadm과 Ansible을 이용한 자동화 배포 도구로, Kubespray를 이용하여 쿠버네티스를 쉽게 설치할 수 있다.

다음의 명령을 실행하여 쿠버네티스 설치를 위한 Kubespray를 다운로드한다.
----
git clone -b tmax-master https://github.com/tmax-cloud/kubespray.git
----

[#Kubespray 환경 설정]
== Kubespray 환경 설정

Kubespray를 실행하기 위한 필수 설정 파일들을 정의한다.

NOTE: Kubespray를 실행하기 위해서는 사전 준비가 필요하다. xref:offline-intro.adoc[설치 전 준비사항]을 참고하여 환경을 구성한다.

. *쿠버네티스 기본 정보 설정*
+
`kubespray/inventory/tmaxcloud/group_vars/all/all.yml` 파일을 열어 Kubernetes의 기본 정보를 설정한다.
+
.예시
----
apiserver_loadbalancer_domain_name: "10.0.10.50" <1> 
loadbalancer_apiserver:
  address: 10.0.10.50 <2>
  port: 6443 <3>
  
upstream_dns_servers: <4>
  - 192.168.1.150  
----
+
<1> (TD: 작성한 내용은 값 작성 방법이므로, 해당 항목의 정의 작성 필요)(QA : 각 쿠버네티스 API 서버와 통신할 수 있는 vip 주소)
<2> (TD: 작성한 내용은 값 작성 방법이므로, 해당 항목의 정의 작성 필요)(QA : 각 쿠버네티스 API 서버와 통신할 수 있는 vip 주소)
<3> 쿠버네티스 API 서버 포트 번호
<4> 도메인 네임서버 주소
 
. *Calico 구성 정보 설정*
+
`kubespray/inventory/tmaxcloud/k8s_cluster/k8s-net-calico.yml` 파일을 열어 Calico 관련 정보를 설정한다.
+
.예시
----
calico_ip_auto_method: "cidr=192.168.7.0/24" <1>
----
+
<1> (QA: calico cidr 설정) (TD: 항목 설명 필요)(QA : calico가 자동으로 감지할 노드들의 CIDR 값 )

. *추가 설치 모듈 설정*
+
`kubespray/inventory/tmaxcloud/k8s_cluster/addons.yml` 파일을 열어 추가 설치가 가능한 모듈 관련 정보를 설정한다.
+
.예시
----
default_storageclass_name: nfs <1>
sc_name_0: nfs <2>
sc_name_999: nfs <3>
nfs_namespace: nfs <4>
nfs_server: 192.168.7.17 <5>
nfs_path: /root/test <6>
----
+
<1> 기본값으로 설정할 스토리지 이름
<2> HyperRegistry에서 Postgres PVC의 스토리지 클래스 이름
<3> 그 외의 PVC 스토리지 클래스 이름
<4> NFS 스토리지 네임스페이스 이름
<5> NFS 서버 주소  
<6> NFS 서버 공유 폴더 경로

. *폐쇄망 정보 설정*
+
`kubespray/inventory/tmaxcloud/group_vars/all/offline.yml` 파일을 열어 폐쇄망 관련 정보를 설정한다.
+
.예시
----
is_this_offline: true <1>
registry_host: "10.0.10.50:5000" <2>
files_repo: "http://172.22.5.2" <3>
----
+
<1> 폐쇄망 환경 여부 (폐쇄망일 경우 true)
<2> 프라이빗 레지스트리 주소
<3> 파일 리포지터리 주소

[#Kubespray 실행]
== Kubespray 실행

ansible-playbook 명령을 사용하여 Kubespray를 실행한다.
----
ansible-playbook -i inventory/tmaxcloud/inventory.ini --become --become-user=root cluster.yml
----

[#환경 설정]
== 환경 설정
(TD: 해당 환경설정 부분이 상단의 "Kubespray 환경 설정"에 포함되어야 하나?)

. *노드 정보 등록*
+ 
`inventory/tmaxcloud/inventory.ini` 파일을 열어 kubespray에서 설치할 노드들의 정보를 등록한다. +
이때 all 그룹은 `*[호스트 이름] [Ansible IP 주소] [Backup IP 주소]*` 형태로 작성하고, 그 외 그룹은 all 그룹에서 정의한 호스트 이름만 작성한다.

. *사용자 지정 도메인 등록*
+
`tmaxcloud/group_vars/k8s_cluster/k8s-cluster.yml` 파일을 열어 외부에 노출할 사용자 지정 도메인의 정보를 등록한다.
+
.예시
----
# Enable extra custom DNS domain - by sophal_hong@tmax.co.kr
enable_local_nip_domain: false <1>
enable_custom_domain: true <2>
custom_domain_name: "cloudqa.com" <3>
custom_domain_ip: 172.22.7.2 <4>
api_server_dns_cfwhn: true <5>
----
+
<1> nip.io 도메인의 사용 여부 (Self-Signed 도메인을 사용할 경우 true)
<2> 커스텀 도메인의 사용 여부 (DNS를 사용할 경우 true)
<3> 프록시 노드에 맵핑된 DNS 이름
<4> 프록시 노드의 IP 주소 
<5> kube-apiserver의 DNS 정책으로 "ClusterFirstWithHostNet" 적용 여부

. *설치할 애플리케이션 구성 정보 확인*
+
Kubespray로 설치될 애플리케이션(`nginx`, `harbor`, `gitlab`, `argocd`)의 구성 정보를 확인 및 설정한다. +
해당 애플리케이션의 구성 정보는 기본적으로 `roles/bootstrap-cloud/defaults/main.yml` 파일에서 설정이 가능하며, 추가적으로 커스터마이징이 필요할 경우에는 `roles/bootstrap-cloud/task/` 및 `roles/bootstrap-cloud/templates/` 하위 파일에서 설정이 가능하다.
+
다음은 인그레스의 서비스 타입을 "NodePort"로 설정하는 예이다.
+
.roles/bootstrap-cloud/defaults/main.yml
----
ingress_nginx_service_type: NodePort
----

. *애플리케이션 설치*
+
ansible-playbook 명령을 사용하여 애플리케이션을 설치한다. 
+
----
ansible-playbook -i inventory/tmaxcloud/inventory.ini --become --become-user=root cluster.yml -t bootstrap-cloud
----

NOTE: 애플리케이션 설치가 정상적으로 완료되면, Gitlab과 ArgoCD 간의 저장소가 자동으로 연동된다.

[#마스터 클러스터 설치]
== 마스터 클러스터 설치

. *master-values.yaml 파일 수정*
+
`application/helm/master-values.yaml` 파일을 열어 애플리케이션을 Helm Chart로 설치하기 위해 사용할 환경 변수를 정의한다.
+
.예시
----
...
global:
  privateRegistry: 10.0.0.1:5000 <1>
...
  gatewayBootstrap:
    enabled: true <2>
    svc_type: NodePort <3>
    tls:
      selfsigned:
        enabled: true <4>
...
----
+
<1> 프라이빗 컨테이너 이미지 레지스트리의 주소
<2> 게이트웨이 부트스트랩의 포함 여부
<3> 네트워크 서비스 타입 
<4> 자체 서명 인증서의 사용 여부
+
NOTE: 예시 외에 설치할 모듈에 대한 enabled 값을 true로 설정하거나, 필요시 사용자 지정 도메인을 등록한다.

. *shared-values.yaml 파일 수정*
+
`application/helm/shared-values.yaml` 파일을 열어 클러스터에 필요한 정보를 설정한다.(TD: shared-values.yaml 파일의 역할이 무엇인가?)(QA : 마스터 클러스터와 싱글 클러스터 설정 정보 중 중복되는 정보들을 shared-values.yaml 에 담아놨습니다. 마스터 클러스터 설정 : master-values.yaml + shared-values.yaml / 싱글 클러스터 설정 : single-values.yaml + shard-values.yaml 입니다.)
+
.예시
----
...
    repoURL: https://gitlab.cloudqa.com/root/argocd-installer.git <1>
...
global:
  network:
    disabled: true <2>
  domain: cloudqa.com <3>
  keycloak:
    domain: hyperauth.cloudqa.com <4>
...
----
<1> ArgoCD와 연동된 Gitlab 저장소 주소 (Gitlab의 경우 url 마지막에 .git을 추가)
<2> 폐쇄망 환경 여부 (폐쇄망일 경우 true)
<3> 애플리케이션 설치 시 인그레스 주소에 사용될 커스텀 도메인 이름
<4> 설치할 HyperAuth 도메인 이름

. *애플리케이션 변수 설정*
+
`application/app_of_apps/master-applications.yaml` 파일을 열어 마스터 클러스터의 애플리케이션 변수를 설정한다.
+
.예시
----
spec:
  ...
  source:
    ...
    repoURL: https://gitlab.cloudqa.com/root/argocd-installer.git <1> 
    targetRevision: {{ target_branch_or_release }} <2> (TD: 실제 예시 데이터 작성)(QA : targetRevision: HEAD) 
----
<1> ArgoCD와 연동된 Gitlab 저장소 주소 (Gitlab의 경우 url 마지막에 .git을 추가)
<2> Gitlab에 연동되어 있는 argocd-installer의 브랜치 이름 (QA: HEAD) (TD: 무엇에 대한 답변인가?) (QA :실제 예시 데이터 작성 예 입니다.)

. *애플리케이션 등록*
+
설치 환경에 애플리케이션을 등록한다.
+
----
$ kubectl -n argocd apply -f application/app_of_apps/master-applications.yaml
----


[#싱글 클러스터 설치]
== 싱글 클러스터 설치

. *애플리케이션 파일 생성*
+
싱글 클러스터 생성을 위해 ArgoCD에 띄울 템플릿 파일을 생성한다. +
이때 생성할 파일의 이름은 `{네임스페이스 이름}-{클러스터 이름}-applications.yaml` 형태로 생성한다.
+
.예시
----
$ cp application/app_of_apps/single-applications.yaml application/app_of_apps/default-cluster-applications.yaml
----

. *애플리케이션 변수 설정*
+
1번 과정에서 생성한 파일에 싱글 클러스터의 애플리케이션 변수를 설정한다. 이때 설정 항목에 대한 자세한 설명은 해당 파일 내의 주석을 참고한다.

. *애플리케이션 등록*
+
1번 과정에서 생성한 파일을 사용하여 마스터 클러스터 환경에 애플리케이션을 등록한다.
+
.예시
----
$ kubectl -n argocd apply -f application/app_of_apps/default-cluster-applications.yaml
----

[#리소스 배포]
== 리소스 배포

애플리케이션 동기화 작업을 통해 리소스를 배포한다.

CAUTION: 애플리케이션 동기화 순서는 다음과 같다. 반드시 순서에 맞게 동기화 작업을 수행한다. + 
1. api-gateway-bootstrap(cert-manager + api-gateway) +
2. strimzi kafka operator +
3. hyperauth +
4. efk or opensearch +
5. prometheus +
6. grafana +
7. istio +
8. jaeger +
9. kiali +
10. cluster-api +
11. cluster-api-provider-aws +
12. cluster-api-provider-vsphere +
13. template-service-broker +
14. catalog-controller +
15. hypercloud +
16. tekton-pipeline +
17. tekton-trigger +
18. cicd-operator +
19. redis-operator +
20. image-validating-webhook +
21. ai-devops

. *ArgoCD 서버 접속*
+
ArgoCD 서버에 접속한 후 로그인한다. 이때 ArgoCD 서버의 주소는 다음의 명령어를 실행하여 확인할 수 있다.
+
----
$ kubectl get svc -n argocd argocd-server
----

. *동기화할 애플리케이션 검색*
+
동기화 작업을 수행할 애플리케이션을 검색한 후 *[sync]* 버튼을 클릭한다.(TD: 화면 캡처를 위한 ArgoCD 접속 URL 및 계정 정보 필요) 
+
image::../images/figure_application_sync_01.png[]

. *동기화 옵션 설정*
+
동기화할 리소스 및 동기화 옵션을 설정한 후 *[SYNCHRONIZE]* 버튼을 클릭한다.
+
image::../images/figure_application_sync_02.png[]

. *상태 확인*
+
애플리케이션의 *Status* 항목에 "Healthy"와 "Synced"가 표시되는지 확인한다.
+
image::../images/figure_application_sync_03.png[]


(QA : argocd-installer로 설치하는 모듈들이 traefik gateway를 사용합니다.) (TD: "nignx ingress-> traefik gateway ingress로 변경 방법" 매뉴얼 포함 여부 QA와 협의 필요)
